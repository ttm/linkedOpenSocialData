\documentclass[review]{elsarticle}

\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{multirow}
\usepackage{pgfplots}
\usepackage{float}
\usepackage{amssymb}
\usepackage{cleveref}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
% \usepackage{changepage}
\usepackage{longtable}
\usepackage{tabularx}
% \usepackage[showframe=true]{geometry}
%
\pgfplotsset{compat=1.5}
\pgfplotsset
{
	width=0.5\textwidth,
	x tick label style={/pgf/number format/1000 sep=},
  enlarge x limits = 0.0,
  ymajorgrids=true,
	major tick style={draw=none},
  ymin = 0.0,
	every axis/.append style={
		every x tick label/.append style={font=\tiny},
    every y tick label/.append style={font=\tiny},
    every axis label/.append style={font=\small},
    height=37mm,
    width=37mm,
    title style={at={(0.5,0.90)}, font=\normalfont},
    xticklabel style={yshift=4pt}
	}
}

%% `Elsevier LaTeX' style
\bibliographystyle{elsarticle-num}
%
\makeatletter
\def\ps@pprintTitle{%
    \let\@oddhead\@empty
    \let\@evenhead\@empty
    \def\@oddfoot{}%
\let\@evenfoot\@oddfoot}
\makeatother
\begin{document}
%
\begin{frontmatter}
%
\title{Linked Open Social Data for Scientific Benchmarking}
%
\author[pwr]{Renato Fabbri\corref{corresponding}\fnref{kio-url}}
\ead{fabbri@usp.br}
%
\author[pwr]{Osvaldo Novais de Oliveira Junior\fnref{kio-url}}
\ead{chu@ifsc.usp.br}
%
\cortext[corresponding]{Corresponding author}
\address[pwr]{S\~ao Carlos Institute of Physics, S\~ao Paulo
University, Brazil}
%
\fntext[kio-url]{\textit{URL:} \url{http://www.ifsc.usp.br/}}
%
\begin{abstract}
The field of social network analysis and the topic of complex networks
are widely researched.
Recently, a myriad of results have been reported which are based in
diverse datasets most often not accessible to other researchers.
This work exposes an open dataset with diverse provenance and oriented
to provide the scientific community a friendly and common repertoire.
Current data was obtained from Facebook, Twitter, IRC, Email and the
detached instances of ParticipaBR, AA and Cidade Democr\'atica.
These were represented as linked data to homonenize access,
conform to current best practices and ease analyzes which integrate third
party and provided instances.
This document presents an outline and overall statistics of the given
dataset which should favor subsequent work.
\end{abstract}
%
\begin{keyword}
Big Data, Data Mining, Benchmark Data, Facebook, Twitter, IRC, Email, Complex Networks
%Hierarchy of Clusters \sep HoC \sep Benchmark Dataset \sep Benchmark Data Generator \sep Artificial Data \sep Cluster Analysis \sep Tree Structured Stick Breaking Process \sep TSSB \sep ...
\end{keyword}

\end{frontmatter}

\section{Introduction}
In recent years, the web of linked data~\cite{lee1} has attracted wide attention in
both research and application realms.
However, there is is a lack of datasets for research benchmarking,
specially in the complex networks field, yielding diverse results from 
poorly related data.

The enormity of the digital data propels a rapid development of analysis methods
from different perspectives.
The used datasets differ within the scope of each research with
scarce and historical exception such as the
karate club dataset~\cite{newmanBook}.
On the other hand, the available linked data is not 
stable or rigorous enough to be
a public reference on statistical physics and social networks research.
 
This work presents a linked open social data (LOSD) dataset with data from diverse
provenance, including Facebook, Twitter, IRC, Email and detached
instances.
Such data is proposed as a common repertoire for scientific
reseach involving networks and textual content.

% \subsection{Benchmarking in the analysis of complexity}

\section{Materials}\label{materials}
Data was gathered either from:
\begin{itemize}
    \item public APIs (Twitter, Email); or
    \item public logs (IRC and AA); or
    \item Netvizz software~\cite{netvizz} (Facebook); or
    \item donated data from users (Facebook); or
    \item donated data from system administrators (AA, ParticipaBR,
        Cidade Democr\'atica).
\end{itemize}

Integration and uniformity of access is obtained through linked data
representation, as exposed in Section~\ref{queries}.

Of central importance to presented LOSD is the concept of a snapshot.
A snapshot is a set of data gathered together, at a contiguous time
unit.
Examples: the first 20 thousand email messages of an email list
comprises a snapshot; the tweets from the MAMA event is a
snapshot; the friendship, interaction and posts structures of a facebook
group, prospected at the same time, is a snapshot.

\subsection{Facebook data}
Friendship ego networks (networks whose reference is an user)
were donated from individual users in 2013 and 2014.
Friendship and interaction networks from groups were gathered from
groups where the first author was a participant.
Additionally, some groups have post texts along some metadata, such as
the number of likes.

\subsection{Twitter data}
Tweets were gathered through the streaming public API.
Each snapshot is unified by a distinct hashtag.
Edges are canonically yield by retweets but replies and user mentions
are also kept in the LOSD.

\subsection{IRC data}
Public IRC logs were used to render LOSD IRC snapshots.
LOSD has record of users to which the message is directed to or
mentions.

\subsection{Email data}
Email snapshots refer to individual email lists.
All messages were taken from the Gmane public email~\cite{gmane}.
Each message has the original text and the text without some of the lines
from previous messages or that are pasted software code.
Most importantly, each message item holds the ID of the message it is
a reply to, if any.

\subsection{ParticipaBR data}
The ParticipaBR is a platform for social participation once regarded as
the Brazilian portal of social participation.
Texts are derived from blog posts and networks are derived from
friendship and interaction criteria.

\subsection{AA data}
The Algorithmic Autoregulation~\cite{aa} is a methodology for testifying
and sharing ongoing work.
The data was gathered from different versions of the system and from IRC
logs and is presented as part of the LOSD as one of the detached
platforms.

\subsection{Cidade Democr\'atica data}
Cidade Democr\'atica is a civil society social participation portal.

\section{Methods}
Data in the presented LOSD is represented as linked open data through
RDF and ontologicaly described through a data-driven ontology synthesis
method.
These steps are described in the following sections.

\subsection{Linked open data}
Linked data refers to data published in the web in such a way that it is
machine readable and conforms to a set of best practices.
The web of data is constructed with documents on the web 
such as the web of hypertext.
In practice, the idea of linked data can me summarized
by 1) the use of RDF to publish data on the web and 2) the use of RDF
links to interlink data from different sources.
The web is expected to be interconnected and to grow by the systematic application of four
steps~\cite{lee1}:
\begin{itemize}
    \item Use URIs to identify things~\cite{uri}.
    \item Use HTTP URIs.
    \item Provide useful information when an URI is accessed via HTTP.
    \item Provide other URIs in the description of resources so human
        and machine agents can perform discovery.
\end{itemize}

The Linked Open Data~\cite{lod} builds an ever growing cloud of data,
the global data space, which is usually
conceived as centered around the DBPedia, a linked data representation
of data from Wikipedia~\cite{dbpedia0,dbpedia}.

\subsection{RDF}
The Resource Description Framework (RDF), a W3C
recommendation, is a model for data
interchange.
It is based on the idea of making statements about resources in the form
of triples, i.e. expressions in the form ``subject - predicate -
object''.
RDF can be serialized in several file formats, including RDF/XML,
Turtle and Manchester all which, in essence, represent a labeled and
directed multi-graph.
RDF may be stored in a type of database called a triplestore~\cite{rdf}.

As an example of an RDF statement, the following triple in the Turtle
format asserts that ``the paper has color white'':\\
\texttt{http://example.org/paper http://example.org/hasColor\\
http://example.org/White .}

\subsection{Data-driven ontology synthesis}
OWL Ontologies are critical tools to describe taxonomies and the
structure of knowledge.
Most ontologies are created by domain experts even though the data they
arrange is often given by a software system.  

We developed an ontology synthesis method that probes the ontological structure in data with
SPARQL queries and post-processing which can be divided in the following steps:
\begin{enumerate}[leftmargin=0cm]
    \item Obtaining all distinct classes with the query:\\
        \texttt{SELECT DISTINCT ?class WHERE \{ ?s a ?class \}}
    \item Obtaining all distinct properties with the query:\\
        \texttt{SELECT DISTINCT ?p WHERE \{ ?s ?p ?o \}}
    \item For each class, get distinct subject classes and predicates where the
        the object is an instance of the class:\\
        \texttt{SELECT DISTINCT ?p ?cs WHERE \{ ?i a <class\_uri> . ?s ?p ?i . ?s
        a ?cs . \}}
    \item For each class, get distinct predicates and object classes or
        datatypes where the subject is an instance of such class:\\
        \texttt{SELECT DISTINCT ?p ?co (datatype(?o) as ?do) WHERE \{ ?i
                a <class\_uri> . ?i ?p ?o . OPTIONAL \{ ?o a ?co . \} \}}
    \item For each property, check if it is functional, i.e. if it
        occurs only once with each subject:\\
        \texttt{SELECT DISTINCT (COUNT(?o) as ?co) WHERE \{ ?s
            <property\_uri> ?o \} GROUP BY ?s}
    \item For each property, find the incident range and domain with the
        queries:\\
        \texttt{SELECT DISTINCT ?co (datatype(?o) as ?do) WHERE \{ ?s
                <property\_uri> ?o . OPTIONAL \{ ?o a ?co . \} \}}
        \texttt{SELECT DISTINCT ?cs WHERE \{ ?s <property\_uri> ?o . ?s a ?cs . \}}
    \item For each instance of each class, get all distinct predicates.
        For each predicate, check if all instances of the class
        hold such relationship (existential restriction):\\
        \texttt{SELECT DISTINCT ?p WHERE \{ ?s a <class\_uri>. ?s ?p ?o
        . \}}\\
        \texttt{SELECT DISTINCT ?s WHERE \{ ?s a <class\_uri> \}}\\
        \texttt{SELECT DISTINCT ?s ?co  (datatype(?o) as ?do) WHERE \{?s
                a <class\_uri>. ?s <property\_uri> ?o . OPTIONAL \{?o a ?co . \}\}}
    \item and if all instances that hold such relationship are instances of the class
        (universal restriction):\\
        \texttt{SELECT DISTINCT ?s WHERE \{ ?s <property\_uri> ?o . \}}
    \item Draw each class, each property and the overall figure.
    \item Make \texttt{rdfs:subClassOf} and \texttt{rdfs:subPropertyOf}
        statements to better organize knowledge and link to third party
        ontologies and data.
\end{enumerate}
 

\section{Results}
\label{outline}
Knowledge Discovery in Databases finished untill data preparation phase.
\subsection{Standardization}
Standards: snapshot ids: <platform>-legacy-<further\_identifier>;
ex: irc-legacy-labmacambira; email-legacy-c++;
facebook-legacy-RenatoFabbri, etc., participants and transactions linkage to
snapshots.

Participation ontology URIs. Concept URIs are the same for different
snapshot provenance, being differetiable by the snapshot metadata.

Big data.
\subsection{Data outline}
Relations only (Facebook), text only (AA, Cidade Democratica).
\input{misc/overallText}
\input{tables/nsnapshots}
\input{tables/basicOverall}
% stats:
%% number of triples
%% number of edges
%% number of chars
%% number of users
% diagrams in the supporting information file
\subsection{Software tools}
The LOSD is released with a software for rendering itself, analyses and
multimedia artifacts.
\subsubsection{Triplification routines}
For each social platform there is a \emph{triplification} routine,
i.e. a script for translating data to RDF.
Original formats and further observations are presented in
Table~\ref{tab:provenance}.
\begin{table*}[h!]\scriptsize
\begin{center}
\caption{Social platforms, original formats and further observations for
the LOSD dataset.}
\begin{tabular}{| l || c | c |}\hline
    \textbf{social platform} & \textbf{original format} & \textbf{further observations} \\\hline\hline
    AA & MySQL and MongoDB databases; IRC text logs & donated by AA users \\\hline
    Cidade Democr√°tica & MySQL database & donated by admins \\\hline
    Email & mbox & obtained through Gmane public database \\\hline
    Facebook & GDF, GML and TAB & obtained through Netvizz~\cite{netvizz} \\\hline
    IRC & plain text log & obtained through Supybot logging \\\hline
    ParticipaBR & PostgreSQL database & donated by admins \\\hline
    Twitter & Json & obtained through Twitter streaming API \\\hline
\end{tabular}\end{center}
\end{table*}                    
\subsubsection{Topological and textual Analysis}
\subsubsection{Multimedia rendering}
\subsection{SPARQL queries}\label{queries}
% all text from user
% users with the most friendships
% users with most interactions
% search string in messages

\section{Conclusions}
\label{conclusions}
The Linked Open Social Data (LOSD) presented in this article
should be available online in the \url{http://linkedopensocialdata.org}
address in near future to fulfill the purpose of being a common
repertoire in current research.
One should access \url{http://wiki.nosdigitais.teia.org.br/LOSD}
for reaching the address where LOSD is currently reachable.

\section*{References}
%
\bibliography{paper}
%\bibliography{myLastBibfile.bib}
%
\end{document}
